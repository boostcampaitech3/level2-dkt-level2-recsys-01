{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config \n",
    "from models.ssakt import SSAKT\n",
    "from dataset import get_dataloaders\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "\n",
    "class SAKTModel(pl.LightningModule):\n",
    "  def __init__(self,model_args,model=\"ssakt\"):\n",
    "    super().__init__()\n",
    "    self.model = SSAKT(**model_args)\n",
    "      \n",
    "  def forward(self,exercise,category,tag,chapter,test,response,etime,\\\n",
    "    assessmentItemID_answer_mean,user_category_acc,test_elapsed,testId_answer_mean,\\\n",
    "      assessmentItemID_answer_sum,assessmentItemID_test_elapsed_mean,\\\n",
    "        user_testId_acc,user_category_mean_telapsed,user_category_correct_answer,\\\n",
    "          testId_answer_sum,testId_test_elapsed_mean,user_testId_mean_telapsed,\\\n",
    "            user_acc,chapter_answer_mean,user_chapter_acc,user_category_cum_telapsed,\\\n",
    "              tag_answer_mean,user_category_total_answer,tag_answer_sum,\\\n",
    "                chapter_answer_sum,user_correct_answer,last_prob,\\\n",
    "                  user_tag_acc,num_tags_per_test,category_answer_mean):\n",
    "    return self.model(exercise,category,tag,chapter,test,response,etime,\\\n",
    "      assessmentItemID_answer_mean,user_category_acc,test_elapsed,testId_answer_mean,\\\n",
    "        assessmentItemID_answer_sum,assessmentItemID_test_elapsed_mean,\\\n",
    "          user_testId_acc,user_category_mean_telapsed,user_category_correct_answer,\\\n",
    "            testId_answer_sum,testId_test_elapsed_mean,user_testId_mean_telapsed,\\\n",
    "              user_acc,chapter_answer_mean,user_chapter_acc,user_category_cum_telapsed,\\\n",
    "                tag_answer_mean,user_category_total_answer,tag_answer_sum,\\\n",
    "                  chapter_answer_sum,user_correct_answer,last_prob,\\\n",
    "                    user_tag_acc,num_tags_per_test,category_answer_mean)\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.parameters())\n",
    "  \n",
    "  def training_step(self,batch,batch_idx):\n",
    "    inputs,target_ids,target,last_question = batch\n",
    "    output = self(inputs[\"input_ids\"],inputs[\"input_cat\"],inputs[\"input_tag\"],inputs[\"input_chap\"],inputs[\"input_test\"],target_ids,inputs[\"input_rtime\"],\n",
    "                  inputs[\"input_assessmentItemID_answer_mean\"],inputs[\"input_user_category_acc\"],inputs[\"input_test_elapsed\"],\n",
    "                  inputs[\"input_testId_answer_mean\"], inputs[\"input_assessmentItemID_answer_sum\"], inputs[\"input_assessmentItemID_test_elapsed_mean\"],\n",
    "                  inputs[\"input_user_testId_acc\"], inputs[\"input_user_category_mean_telapsed\"], inputs[\"input_user_category_correct_answer\"],\n",
    "                  inputs[\"input_testId_answer_sum\"], inputs[\"input_testId_test_elapsed_mean\"], inputs[\"input_user_testId_mean_telapsed\"],\n",
    "                  inputs[\"input_user_acc\"], inputs['input_chapter_answer_mean'], inputs[\"input_user_chapter_acc\"], inputs['input_user_category_cum_telapsed'],\n",
    "                  inputs[\"input_tag_answer_mean\"], inputs[\"input_user_category_total_answer\"], inputs[\"input_tag_answer_sum\"],\n",
    "                  inputs[\"input_chapter_answer_sum\"], inputs[\"input_user_correct_answer\"], inputs[\"input_last_prob\"],\n",
    "                  inputs[\"input_user_tag_acc\"], inputs[\"input_num_tags_per_test\"], inputs[\"input_category_answer_mean\"])\n",
    "    target_mask = (target_ids != 0)\n",
    "    output = torch.masked_select(output.squeeze(),target_mask)\n",
    "    target = torch.masked_select(target,target_mask)\n",
    "    loss = nn.BCEWithLogitsLoss()(output.float(),target.float())\n",
    "    return {\"loss\":loss,\"output\":output,\"target\":target}\n",
    "\n",
    "  def training_epoch_end(self, training_ouput):\n",
    "      output = np.concatenate([i[\"output\"].cpu().detach().numpy()\n",
    "                              for i in training_ouput]).reshape(-1)\n",
    "      target = np.concatenate([i[\"target\"].cpu().detach().numpy()\n",
    "                                  for i in training_ouput]).reshape(-1)\n",
    "      print(\"train output length\", len(output), output.shape)\n",
    "      accuracy = accuracy_score(target, [1 if x > 0.5 else 0 for x in output])\n",
    "      auc = roc_auc_score(target, output)\n",
    "      self.print(\"train auc: \", auc, \" acc: \", accuracy)\n",
    "      self.log(\"train_auc\", auc)\n",
    "      self.log(\"train_acc\", accuracy)\n",
    "  \n",
    "  def validation_step(self,batch,batch_idx):\n",
    "    inputs,target_ids,target,last_question = batch\n",
    "    output = self(inputs[\"input_ids\"],inputs[\"input_cat\"],inputs[\"input_tag\"],inputs[\"input_chap\"],inputs[\"input_test\"],target_ids,inputs[\"input_rtime\"],\n",
    "                  inputs[\"input_assessmentItemID_answer_mean\"],inputs[\"input_user_category_acc\"],inputs[\"input_test_elapsed\"],\n",
    "                  inputs[\"input_testId_answer_mean\"], inputs[\"input_assessmentItemID_answer_sum\"], inputs[\"input_assessmentItemID_test_elapsed_mean\"],\n",
    "                  inputs[\"input_user_testId_acc\"], inputs[\"input_user_category_mean_telapsed\"], inputs[\"input_user_category_correct_answer\"],\n",
    "                  inputs[\"input_testId_answer_sum\"], inputs[\"input_testId_test_elapsed_mean\"], inputs[\"input_user_testId_mean_telapsed\"],\n",
    "                  inputs[\"input_user_acc\"], inputs['input_chapter_answer_mean'], inputs[\"input_user_chapter_acc\"], inputs['input_user_category_cum_telapsed'],\n",
    "                  inputs[\"input_tag_answer_mean\"], inputs[\"input_user_category_total_answer\"], inputs[\"input_tag_answer_sum\"],\n",
    "                  inputs[\"input_chapter_answer_sum\"], inputs[\"input_user_correct_answer\"], inputs[\"input_last_prob\"],\n",
    "                  inputs[\"input_user_tag_acc\"], inputs[\"input_num_tags_per_test\"], inputs[\"input_category_answer_mean\"])\n",
    "    target_mask = (last_question == -1)\n",
    "    output = torch.masked_select(output.squeeze(),target_mask)\n",
    "    target = torch.masked_select(target,target_mask)\n",
    "    loss = nn.BCEWithLogitsLoss()(output.float(),target.float())\n",
    "    return {\"val_loss\":loss,\"output\":output,\"target\":target}\n",
    "\n",
    "  def validation_epoch_end(self, validation_ouput):\n",
    "      output = np.concatenate([i[\"output\"].cpu().detach().numpy()\n",
    "                            for i in validation_ouput]).reshape(-1)\n",
    "      target = np.concatenate([i[\"target\"].cpu().detach().numpy()\n",
    "                               for i in validation_ouput]).reshape(-1)\n",
    "      print(\"val output length\", len(output), output.shape)\n",
    "      accuracy = accuracy_score(target, [1 if x > 0.5 else 0 for x in output])\n",
    "      auc = roc_auc_score(target, output)\n",
    "      self.print(\"val auc: \", auc, \" acc: \", accuracy)\n",
    "      self.log(\"val_auc\", auc)\n",
    "      self.log(\"val_acc\", accuracy)\n",
    "\n",
    "  def predict_step(self,batch,batch_idx):\n",
    "      inputs,target_ids,target,last_question = batch\n",
    "      output = self(inputs[\"input_ids\"],inputs[\"input_cat\"],inputs[\"input_tag\"],inputs[\"input_chap\"],inputs[\"input_test\"],target_ids,inputs[\"input_rtime\"],\n",
    "                    inputs[\"input_assessmentItemID_answer_mean\"],inputs[\"input_user_category_acc\"],inputs[\"input_test_elapsed\"],\n",
    "                    inputs[\"input_testId_answer_mean\"], inputs[\"input_assessmentItemID_answer_sum\"], inputs[\"input_assessmentItemID_test_elapsed_mean\"],\n",
    "                    inputs[\"input_user_testId_acc\"], inputs[\"input_user_category_mean_telapsed\"], inputs[\"input_user_category_correct_answer\"],\n",
    "                    inputs[\"input_testId_answer_sum\"], inputs[\"input_testId_test_elapsed_mean\"], inputs[\"input_user_testId_mean_telapsed\"],\n",
    "                    inputs[\"input_user_acc\"], inputs['input_chapter_answer_mean'], inputs[\"input_user_chapter_acc\"], inputs['input_user_category_cum_telapsed'],\n",
    "                    inputs[\"input_tag_answer_mean\"], inputs[\"input_user_category_total_answer\"], inputs[\"input_tag_answer_sum\"],\n",
    "                    inputs[\"input_chapter_answer_sum\"], inputs[\"input_user_correct_answer\"], inputs[\"input_last_prob\"],\n",
    "                    inputs[\"input_user_tag_acc\"], inputs[\"input_num_tags_per_test\"], inputs[\"input_category_answer_mean\"])\n",
    "      target_mask = (last_question == -1)\n",
    "      output = torch.masked_select(output.squeeze(),target_mask)\n",
    "      return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading csv.....\n",
      "shape of dataframe : (2526700, 35)\n",
      "no. of skills : 9454\n",
      "no. of categories:  1637\n",
      "no. of tags:  1012\n",
      "shape after exlusion: (2526700, 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/input/Knowledge-Tracing/dataset.py:329: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"last_question\"] = test_df[\"answered_correctly\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df size (260114, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/input/Knowledge-Tracing/dataset.py:334: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"last_question\"] = [-1 if is_bool else 1 for is_bool in train_df.user_id != train_df.user_id.shift(-1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping users...\n",
      "splitting\n",
      "train size:  (5358,) validation size:  (1340,) test size:  (744,)\n",
      "Int64Index([2105, 2931, 551, 6632, 4559, 1163, 5377, 7343, 1211, 6144], dtype='int64', name='user_id')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=21)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:06<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 31/31 [00:03<00:00,  7.83it/s]\n"
     ]
    }
   ],
   "source": [
    "########### TRAINING AND SAVING MODEL #######\n",
    "\n",
    "train_loader, val_loader, test_loader = get_dataloaders()\n",
    "\n",
    "ARGS = {\"n_dims\":config.EMBED_DIMS ,\n",
    "            'n_encoder':config.NUM_ENCODER,\n",
    "            'n_decoder':config.NUM_ENCODER,\n",
    "            'enc_heads':config.ENC_HEADS,\n",
    "            'dec_heads':config.ENC_HEADS,\n",
    "            'total_ex':9455,\n",
    "            'total_cat':1538,\n",
    "            'total_tag':913,\n",
    "            'total_chap':448,\n",
    "            'total_responses':9455,\n",
    "            'total_test':199,\n",
    "            'seq_len':config.MAX_SEQ}\n",
    "\n",
    "model_name = \"ssakt\"\n",
    "datenow = datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
    "\n",
    "# checkpoint path\n",
    "PATH = \"./checkpoint/ssakt/ckpt/2022_05_12-01_05_35_AM-epoch=13-val_auc=0.78474.ckpt\" \n",
    "sakt_model = SAKTModel(model=model_name,model_args=ARGS)\n",
    "trainer = pl.Trainer(gpus=-1,progress_bar_refresh_rate=21) \n",
    "sakt_model.load_state_dict(torch.load(PATH)[\"state_dict\"])\n",
    "a = trainer.predict(sakt_model, val_loader)\n",
    "b = trainer.predict(sakt_model, test_loader)\n",
    "\n",
    "# get validation result\n",
    "valid_output = []\n",
    "valid_result = []\n",
    "for i in range(len(a)):\n",
    "  valid_output.extend(a[i][0].tolist())\n",
    "  valid_result.extend(a[i][1].tolist())\n",
    "valid_ssakt_220512 = pd.DataFrame({\"y_valid\":valid_output, \"ssakt_preds\":valid_result})\n",
    "\n",
    "# get test prediction result\n",
    "result = []\n",
    "for i in range(len(b)):\n",
    "  result.extend(b[i][1].tolist())\n",
    "\n",
    "sample_submission = pd.read_csv(\"/opt/ml/input/data/sample_submission.csv\")\n",
    "sample_submission[\"prediction\"] = result\n",
    "\n",
    "path = \"./checkpoint/\"+model_name+\"/submission/\"\n",
    "\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path)\n",
    "\n",
    "if not isExist:\n",
    "  \n",
    "  # Create a new directory because it does not exist \n",
    "  os.makedirs(path)\n",
    "  print(\"The new directory is created!\")\n",
    "\n",
    "sample_submission.to_csv(path+datenow+\"_\"+model_name+\"_epoch=13-val_auc=0.78474.csv\", index=False)\n",
    "valid_ssakt_220512.to_csv(path+datenow+\"_\"+model_name+\"_valid_ssakt_220512.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
